{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1acbcc6",
   "metadata": {},
   "source": [
    "# Introduction aux Modèles de Diffusion\n",
    "\n",
    "Ce notebook présente les concepts fondamentaux des modèles de diffusion dans le contexte de l'intelligence artificielle générative.\n",
    "\n",
    "## Table des matières\n",
    "1. [Vérification de l'environnement](#verification)\n",
    "2. [Théorie des modèles de diffusion](#theorie)\n",
    "3. [Premier exemple avec Diffusers](#exemple)\n",
    "4. [Génération d'images simples](#generation)\n",
    "5. [Visualisation des résultats](#visualisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139679a7",
   "metadata": {},
   "source": [
    "## 1. Vérification de l'environnement {#verification}\n",
    "\n",
    "Commençons par vérifier que toutes les dépendances nécessaires sont installées et fonctionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48732c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA disponible: False\n",
      "Utilisation du CPU\n"
     ]
    }
   ],
   "source": [
    "# Import des bibliothèques essentielles\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import CLIPTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU détecté: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Utilisation du CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125d249",
   "metadata": {},
   "source": [
    "## 2. Théorie des modèles de diffusion {#theorie}\n",
    "\n",
    "Les modèles de diffusion sont une classe de modèles génératifs qui apprennent à générer des données en simulant un processus de diffusion inverse.\n",
    "\n",
    "### Processus de diffusion directe\n",
    "Le processus directe ajoute progressivement du bruit gaussien à une image jusqu'à obtenir du bruit pur.\n",
    "\n",
    "### Processus de diffusion inverse\n",
    "Le modèle apprend à inverser ce processus, en partant du bruit pour reconstruire une image cohérente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation simple du processus de diffusion\n",
    "def simulate_diffusion_process(image, num_steps=1000):\n",
    "    \"\"\"\n",
    "    Simule le processus de diffusion directe en ajoutant du bruit progressivement\n",
    "    \"\"\"\n",
    "    noisy_images = []\n",
    "    current_image = image.copy()\n",
    "    \n",
    "    for t in range(0, num_steps, num_steps//10):\n",
    "        # Calcul du niveau de bruit basé sur un planning linéaire\n",
    "        noise_level = t / num_steps\n",
    "        noise = np.random.normal(0, 1, image.shape)\n",
    "        \n",
    "        # Ajout du bruit à l'image\n",
    "        noisy_image = (1 - noise_level) * image + noise_level * noise\n",
    "        noisy_images.append(noisy_image)\n",
    "    \n",
    "    return noisy_images\n",
    "\n",
    "# Création d'une image simple pour la démonstration\n",
    "original_image = np.zeros((64, 64))\n",
    "original_image[20:44, 20:44] = 1.0  # Carré blanc\n",
    "\n",
    "# Simulation du processus de diffusion\n",
    "noisy_sequence = simulate_diffusion_process(original_image)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, img in enumerate(noisy_sequence):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(f'Étape {i+1}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Processus de diffusion directe')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb6e6d",
   "metadata": {},
   "source": [
    "## 3. Premier exemple avec Diffusers {#exemple}\n",
    "\n",
    "Utilisons maintenant la bibliothèque Diffusers pour charger un modèle pré-entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du modèle\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Chargement du modèle {model_id} sur {device}...\")\n",
    "print(\"Cela peut prendre quelques minutes lors du premier lancement.\")\n",
    "\n",
    "# Chargement du pipeline\n",
    "try:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        variant=\"fp16\" if device == \"cuda\" else None\n",
    "    )\n",
    "    pipe = pipe.to(device)\n",
    "    print(\"Modèle chargé avec succès !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du modèle: {e}\")\n",
    "    print(\"Vous pourriez avoir besoin d'une connexion internet pour télécharger le modèle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f71af0",
   "metadata": {},
   "source": [
    "## 4. Génération d'images simples {#generation}\n",
    "\n",
    "Maintenant, générons quelques images à partir de descriptions textuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eacafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts de test\n",
    "prompts = [\n",
    "    \"a beautiful sunset over mountains\",\n",
    "    \"a cute cat sitting on a book\",\n",
    "    \"a futuristic city with flying cars\",\n",
    "    \"a peaceful garden with flowers\"\n",
    "]\n",
    "\n",
    "# Génération d'images\n",
    "generated_images = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Génération pour: '{prompt}'\")\n",
    "    try:\n",
    "        # Génération avec paramètres optimisés pour la rapidité\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=20,  # Réduction du nombre d'étapes pour la rapidité\n",
    "            guidance_scale=7.5,      # Contrôle de l'adhésion au prompt\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "        \n",
    "        generated_images.append((prompt, image))\n",
    "        print(\"✓ Génération réussie\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Erreur lors de la génération: {e}\")\n",
    "        generated_images.append((prompt, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b0dfe",
   "metadata": {},
   "source": [
    "## 5. Visualisation des résultats {#visualisation}\n",
    "\n",
    "Affichons les images générées avec leurs prompts correspondants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab586cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats\n",
    "num_images = len([img for prompt, img in generated_images if img is not None])\n",
    "\n",
    "if num_images > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    idx = 0\n",
    "    for prompt, image in generated_images:\n",
    "        if image is not None and idx < 4:\n",
    "            axes[idx].imshow(image)\n",
    "            axes[idx].set_title(f\"'{prompt}'\", fontsize=10, wrap=True)\n",
    "            axes[idx].axis('off')\n",
    "            idx += 1\n",
    "    \n",
    "    # Masquer les axes non utilisés\n",
    "    for i in range(idx, 4):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Images générées par le modèle de diffusion', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune image n'a pu être générée. Vérifiez votre configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd090d8c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans ce notebook d'introduction, nous avons :\n",
    "\n",
    "1. ✅ Vérifié l'installation des dépendances\n",
    "2. ✅ Exploré la théorie des modèles de diffusion\n",
    "3. ✅ Simulé le processus de diffusion directe\n",
    "4. ✅ Chargé un modèle Stable Diffusion pré-entraîné\n",
    "5. ✅ Généré des images à partir de descriptions textuelles\n",
    "\n",
    "### Prochaines étapes\n",
    "\n",
    "Dans les prochains notebooks, nous approfondirons :\n",
    "- L'architecture détaillée des modèles de diffusion\n",
    "- Les techniques d'optimisation et de fine-tuning\n",
    "- L'utilisation avancée des prompts\n",
    "- L'intégration avec d'autres modèles génératifs\n",
    "\n",
    "### Ressources supplémentaires\n",
    "\n",
    "- [Documentation Diffusers](https://huggingface.co/docs/diffusers/)\n",
    "- [Papier original DDPM](https://arxiv.org/abs/2006.11239)\n",
    "- [Stable Diffusion](https://arxiv.org/abs/2112.10752)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
